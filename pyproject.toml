[build-system]
requires = ["setuptools>=40.8.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "lmeval_add"
version = "0.1.0"
authors = [
    {name="Nelson Yalta", email="nelson.yalta@ieee.org"}
]
description = "A framework for evaluating language models - Additionals"
readme = "README.md"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
requires-python = ">=3.8"
license = { "text" = "MIT" }
dependencies = [
    "accelerate>=0.21.0",
    "evaluate",
    "datasets>=2.14.0",
    "jsonlines",
    "numexpr",
    "peft>=0.2.0",
    "pybind11>=2.6.2",
    "pytablewriter",
    "rouge-score>=0.0.4",
    "sacrebleu>=1.5.0",
    "scikit-learn>=0.24.1",
    "sqlitedict",
    "torch>=1.8",
    "tqdm-multiprocess",
    "transformers>=4.1",
    "zstandard",
]

[tool.setuptools.packages.find]
include = ["lmeval_add*"]

# required to include yaml files in pip installation
[tool.setuptools.package-data]
lmeval_add = ["**/*.yaml", "tasks/**/*"]

[project.urls]
Homepage = "https://github.com/Fhrozen/LMEvalHarness"

[project.optional-dependencies]
ja = [
    "sentencepiece>=0.1.98",
    "protobuf>=4.22.1",
    "neologdn>=0.5.1",
    "emoji>=2.1.0",
    "fugashi[unidic-lite]",
    "mojimoji>=0.0.12",
]
lm_eval_harness = [
    "lm_eval @ git+https://github.com/EleutherAI/lm-evaluation-harness.git"
]

all = [
    "lmeval_add[lm_eval_harness]",
    "lmeval_add[ja]",
]

[tool.ruff.lint]
extend-select = ["I"]

[tool.ruff.isort]
lines-after-imports = 2
known-first-party = ["lm_eval"]

[tool.ruff.extend-per-file-ignores]
"__init__.py" = ["F401","F402","F403","I"]
"lm_eval/tasks/*"= ["E721"]
