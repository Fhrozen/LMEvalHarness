# LMEvalHarness

Custom Evaluations for LM-Evaluation-Harness (JP &amp; Others)


## JP Language Model Evaluation Harness

Copied from: https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable

## Leaderboard
| model                                                                                                                                                                                                                                                 |   average |   jcommonsenseqa |   jnli |   marc_ja |   jsquad |   jaqket_v2 |   xlsum_ja |   xwinograd_ja |   mgsm | eval script                                                                                                                                                                                                                                                                                                                                                     |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------:|-----------------:|-------:|----------:|---------:|------------:|-----------:|---------------:|-------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| <a target="_blank" href="https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai-japanese-stablelm-instruct-alpha-7b</a> |     54.71 |            82.22 |  52.05 |     82.88 |    63.26 |       74.83 |       7.79 |          72.68 |    2   | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/stabilityai/stabilityai-japanese-stablelm-instruct-alpha-7b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/stabilityai/stabilityai-japanese-stablelm-instruct-alpha-7b/harness.sh</a> |
| <a target="_blank" href="https://huggingface.co/stabilityai/japanese-stablelm-base-alpha-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai-japanese-stablelm-base-alpha-7b</a>         |     51.06 |            33.42 |  43.34 |     96.73 |    70.62 |       78.09 |      10.65 |          72.78 |    2.8 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/stabilityai/stabilityai-japanese-stablelm-base-alpha-7b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/stabilityai/stabilityai-japanese-stablelm-base-alpha-7b/harness.sh</a>         |
| <a target="_blank" href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-sft" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-bilingual-gpt-neox-4b-instruction-sft</a>         |     47.75 |            49.51 |  47.08 |     95.28 |    55.99 |       61.17 |       5.51 |          64.65 |    2.8 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-bilingual-gpt-neox-4b-instruction-sft/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-bilingual-gpt-neox-4b-instruction-sft/harness.sh</a>                     |
| <a target="_blank" href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-ppo" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-bilingual-gpt-neox-4b-instruction-ppo</a>         |     47.18 |            48.79 |  48.23 |     96.09 |    54.16 |       57.65 |       5.03 |          65.07 |    2.4 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-bilingual-gpt-neox-4b-instruction-ppo/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-bilingual-gpt-neox-4b-instruction-ppo/harness.sh</a>                     |
| <a target="_blank" href="https://huggingface.co/llama2/13b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama2-13b-chat</a>                                                                 |     47.02 |            72.56 |  35.62 |     59.92 |    67.69 |       48.2  |      15.14 |          63.82 |   13.2 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/llama2/llama2-13b-chat/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/llama2/llama2-13b-chat/harness.sh</a>                                                                           |
| <a target="_blank" href="https://huggingface.co/llama2/13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama2-13b</a>                                                                           |     46.32 |            74.89 |  21.98 |     38.89 |    76.14 |       67.7  |      18.11 |          62.88 |   10   | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/llama2/llama2-13b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/llama2/llama2-13b/harness.sh</a>                                                                                     |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-neox-3.6b-instruction-ppo</a>       |     46.32 |            44.06 |  54.19 |     89.61 |    51.62 |       50.95 |       6.63 |          69.13 |    4.4 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-ppo/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-ppo/harness.sh</a>                   |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft-v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-neox-3.6b-instruction-sft-v2</a> |     45.23 |            40.57 |  53.45 |     89.88 |    44.91 |       52.84 |       6.14 |          71.22 |    2.8 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-sft-v2/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-sft-v2/harness.sh</a>             |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-neox-3.6b-instruction-sft</a>       |     43.82 |            38.07 |  44.58 |     90.62 |    47.41 |       53.69 |       4.74 |          69.45 |    2   | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-sft/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-neox-3.6b-instruction-sft/harness.sh</a>                   |
| <a target="_blank" href="https://huggingface.co/llama2/7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama2-7b</a>                                                                             |     42.96 |            52.64 |  28.23 |     86.05 |    58.4  |       38.83 |       9.32 |          64.65 |    5.6 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/llama2/llama2-7b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/llama2/llama2-7b/harness.sh</a>                                                                                       |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-neox-3.6b</a>                                       |     41.79 |            31.64 |  34.43 |     74.82 |    47.91 |       68.38 |       5.16 |          70.8  |    1.2 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-neox-3.6b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-neox-3.6b/harness.sh</a>                                                   |
| <a target="_blank" href="https://huggingface.co/llama2/7b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama2-7b-chat</a>                                                                   |     41.31 |            55.59 |  29.54 |     90.41 |    59.34 |       17.96 |       2.34 |          66.11 |    9.2 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/llama2/llama2-7b-chat/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/llama2/llama2-7b-chat/harness.sh</a>                                                                             |
| <a target="_blank" href="https://huggingface.co/rinna/bilingual-gpt-neox-4b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-bilingual-gpt-neox-4b</a>                                         |     40.03 |            20.82 |  55.22 |     59.55 |    50.79 |       59.45 |       5.55 |          66.42 |    2.4 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-bilingual-gpt-neox-4b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-bilingual-gpt-neox-4b/harness.sh</a>                                                     |
| <a target="_blank" href="https://huggingface.co/cyberagent/open-calm-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">cyberagent-open-calm-7b</a>                                                 |     38.8  |            24.22 |  37.63 |     74.12 |    45.79 |       60.74 |       2.04 |          65.07 |    0.8 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/cyberagent/cyberagent-open-calm-7b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/cyberagent/cyberagent-open-calm-7b/harness.sh</a>                                                   |
| <a target="_blank" href="https://huggingface.co/cyberagent/open-calm-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">cyberagent-open-calm-3b</a>                                                 |     38.61 |            27.79 |  40.35 |     86.21 |    40.45 |       46.91 |       1.95 |          63.61 |    1.6 | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/cyberagent/cyberagent-open-calm-3b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/cyberagent/cyberagent-open-calm-3b/harness.sh</a>                                                   |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-1b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-1b</a>                                                     |     36.92 |            34.76 |  37.67 |     87.86 |    26.18 |       37.03 |       5.34 |          64.55 |    2   | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-1b/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-1b/harness.sh</a>                                                                 |
| <a target="_blank" href="https://huggingface.co/rinna/japanese-gpt-neox-small" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna-japanese-gpt-neox-small</a>                                                     |     31.12 |            34.22 |  30.11 |     83.35 |    5.80 |       31.78 |       3.85 |          57.24 |    1.6   | <a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable/models/rinna/rinna-japanese-gpt-neox-small/harness.sh" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">models/rinna/rinna-japanese-gpt-neox-small/harness.sh</a>

## How to evaluate your model

1. git clone https://github.com/Fhrozen/LMEvalHarness
    ```bash
    git clone https://github.com/Fhrozen/LMEvalHarness
    cd LMEvalHarness
    pip install -e ".[ja]"
    ```
2. Choose your prompt template based on [docs/prompt_templates.md]((https://github.com/Stability-AI/lm-evaluation-harness/blob/jp-stable/docs/prompt_templates.md))

3. Run!
   ```python
   lm_eval --model hf \
    --model_args pretrained=EleutherAI/gpt-j-6B \
    --tasks hellaswag \
    --device cuda:0 \
    --batch_size 8
   ```

We evaluated some open-sourced Japanese LMs. Pleasae refer to `harness.sh` inside `models` folder.


## JP Tasks
For more details, please see [docs/jptasks.md](https://github.com/Stability-AI/lm-evaluation-harness/blob/jp-stable/docs/jptasks.md).

| Tasks | [Supported Prompt Templates](https://github.com/Stability-AI/lm-evaluation-harness/blob/jp-stable/docs/prompt_templates.md) |
| :- | -: |
| JSQuAD | 0.1 / 0.2 / 0.3 / 0.4 |
| JCommonsenseQA |  0.1 / 0.2 / 0.3 / 0.4 |
| JNLI | 0.2 / 0.3 / 0.4 |
| MARC-ja | 0.2 / 0.3 / 0.4 |
| JaQuAD | 0.1 / 0.2 / 0.3 / 0.4 |
| JBLiMP | - |
| XLSum-ja | 0.0 / 0.3 / 0.4 |
| JAQKET | 0.1 / 0.2 / 0.3 / 0.4 |

-----------------
